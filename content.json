{"pages":[{"title":"关于","text":"","link":"/blog-cn/about/"}],"posts":[{"title":"My-First-Blog","text":"使用AWS运行代码","link":"/blog-cn/blog-cn/60634/My-First-Blog/"},{"title":"My second blog","text":"使用AWS运行代码","link":"/blog-cn/blog-cn/8343/My-second-blog/"},{"title":"article title","text":"使用AWS运行代码","link":"/blog-cn/blog-cn/46815/article-title/"},{"title":"aws","text":"使用AWS运行代码当本地机器的计算资源有限时，我们可以通过云计算服务获取更强大的计算资源来运行本书中的深度学习代码。本节将介绍如何在AWS（亚马逊的云计算服务）上申请实例并通过Jupyter笔记本运行代码。本节中的例子有如下两个步骤: 申请含一个K80 GPU的“p2.xlarge”实例。 安装CUDA及相应GPU版本的MXNet。 申请其他类型的实例或安装其他版本的MXNet的方法同本节类似。 申请账号并登陆首先，我们需要在 https://aws.amazon.com/ 网站上创建账号。这通常需要一张信用卡。需要注意的是，AWS中国需要公司实体才能注册。如果你是个人用户，请注册AWS全球账号。 登陆AWS账号后，点击图11.8红框中的“EC2”进入EC2面板。 创建并运行EC2实例图11.9展示了EC2面板的界面。在图11.9右上角红框处选择离我们较近的数据中心来减低延迟。我们可以选离国内较近的亚太地区，例如Asia Pacific（Seoul）。注意，有些数据中心可能没有GPU实例。点击图11.9下方红框内“Launch Instance”按钮启动实例。 图11.10的最上面一行显示了配置实例所需的7个步骤。在第一步“1. Chosse AMI”中，选择Ubuntu 16.04作为操作系统。 EC2提供了大量不同配置的实例。如图11.11所示，在第二步“2. Chosse Instance Type”中，选择有一个K80 GPU的“p2.xlarge”实例。我们也可以选择像“p2.16xlarge”这样有多个GPU的实例。如果你想比较不同实例的机器配置和收费，可参考 https://www.ec2instances.info/ 。 我们建议在选择实例前先在图11.9左栏“Limits”标签里检查下有无数量限制。如图11.12所示，该账号的限制是最多在一个区域开一个“p2.xlarge”实例。如果需要开更多实例，可以通过点击右边“Request limit increase”链接来申请更大的实例容量。这通常需要一个工作日来处理。 我们将保持第三步“3. Configure Instance”、第五步“5. Add Tags”和第六步“6. Configure Security Group”中的默认配置不变。点击第四步“4.Add Storage”，如图11.13所示，将默认的硬盘大小增大到40GB。注意，安装CUDA需要4GB左右空间。 最后，在第七步“7. Review”中点击“Launch”来启动配置好的实例。这时候会提示我们选择用来访问实例的密钥。如果没有的话，可以选择图11.14中第一个下拉菜单的“Create a new key pair”选项来生成秘钥。之后，我们通过该下拉菜单的“Choose an existing key pair”选项选择生成好的密钥。点击“Launch Instances”按钮启动创建好的实例。 点击图11.15中的实例ID就可以查看该实例的状态了。 如图11.16所示，当实例状态（Instance State）变绿后，右击实例并选择“Connect”，这时就可以看到访问该实例的方法了。例如在命令行输入 1ssh -i &quot;/path/to/key.pem&quot; ubuntu@ec2-xx-xxx-xxx-xxx.y.compute.amazonaws.com 其中“/path/to/key.pem”是本地存放访问实例的密钥的路径。当命令行提示“Are you sure you want to continue connecting (yes/no)”时，键入“yes”并按回车键即可登录创建好的实例。 安装CUDA如果你登录的是一个GPU实例，需要下载并安装CUDA。首先，更新并安装编译需要的包： 1sudo apt-get update &amp;&amp; sudo apt-get install -y build-essential git libgfortran3 Nvidia一般每年会更新一次CUDA大版本。这里我们下载作者写本书时的最新版本CUDA 9.1。访问Nvidia官网（https://developer.nvidia.com/cuda-91-download-archive ）获取正确 版本的CUDA 9.1的下载地址，如图11.17所示。 获取下载地址后，我们将下载并安装CUDA9.1，例如 12wget https://developer.download.nvidia.com/compute/cuda/9.1/secure/Prod/local_installers/cuda_9.1.85_387.26_linux.runsudo sh cuda_9.1.85_387.26_linux.run 点击“Ctrl+C”跳出文档浏览，并回答以下几个问题。 123456789101112131415accept/decline/quit: acceptInstall NVIDIA Accelerated Graphics Driver for Linux-x86_64 387.26?(y)es/(n)o/(q)uit: yDo you want to install the OpenGL libraries?(y)es/(n)o/(q)uit [ default is yes ]: yDo you want to run nvidia-xconfig?(y)es/(n)o/(q)uit [ default is no ]: nInstall the CUDA 9.1 Toolkit?(y)es/(n)o/(q)uit: yEnter Toolkit Location [ default is /usr/local/cuda-9.1 ]:Do you want to install a symbolic link at /usr/local/cuda?(y)es/(n)o/(q)uit: yInstall the CUDA 9.1 Samples?(y)es/(n)o/(q)uit: n 当安装完成后，运行下面的命令就可以看到该实例的GPU了。 1nvidia-smi 最后，将CUDA加入到库的路径中，以方便其他库找到它。 1echo &quot;export LD_LIBRARY_PATH=\\${LD_LIBRARY_PATH}:/usr/local/cuda-9.1/lib64&quot; &gt;&gt; .bashrc 获取本书代码并安装GPU版的MXNet我们已在“获取和运行本书代码”一节中介绍了Linux用户获取本书代码并安装运行环境的方法。首先，安装Linux版的Miniconda（网址：https://conda.io/miniconda.html ），例如 12wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.shbash Miniconda3-latest-Linux-x86_64.sh 这时需要回答下面几个问题： 12345Do you accept the license terms? [yes|no][no] &gt;&gt;&gt; yesDo you wish the installer to prepend the Miniconda3 install locationto PATH in your /home/ubuntu/.bashrc ? [yes|no][no] &gt;&gt;&gt; yes 安装完成后，运行一次source ~/.bashrc让CUDA和conda生效。接下来，下载本书代码、安装并激活conda环境。 12345mkdir gluon_tutorials_zh &amp;&amp; cd gluon_tutorials_zhcurl https://zh.gluon.ai/gluon_tutorials_zh.tar.gz -o tutorials.tar.gztar -xzvf tutorials.tar.gz &amp;&amp; rm tutorials.tar.gzconda env create -f environment.ymlsource activate gluon 默认环境里安装了CPU版本的MXNet。现在我们将它替换成GPU版本的MXNet。因为CUDA的版本是9.1，所以安装mxnet-cu91。一般来说，如果CUDA版本是x.y，那么相应安装mxnet-cuxy。 12pip uninstall mxnetpip install mxnet-cu91 运行Jupyter笔记本现在，我们可以运行Jupyter笔记本了： 1jupyter notebook 图11.18显示了运行后可能的输出，其中最后一行为8888端口下的URL。 由于创建的实例并没有暴露8888端口，我们可以在本地命令行启动ssh从实例映射到本地8889端口。 12# 该命令须在本地命令行运行。ssh -i &quot;/path/to/key.pem&quot; ubuntu@ec2-xx-xxx-xxx-xxx.y.compute.amazonaws.com -L 8889:localhost:8888 最后，把图11.18中运行Jupyter笔记本后输出的最后一行URL复制到本地浏览器，并将8888改为8889。点击回车键即可从本地浏览器通过Jupyter笔记本运行实例上的代码。 关闭不使用的实例因为云服务按使用时长计费，我们通常会在不使用实例时将其关闭。 如果较短时间内还将重新开启实例，右击图11.16中的示例，选择“Instance State” $\\rightarrow$ “Stop”将实例停止，等下次使用时选择“Instance State” $\\rightarrow$ “Start”重新开启实例。这种情况下，开启的实例将保留其停止前硬盘上的存储（例如无需再安装CUDA和其他运行环境）。然而，停止状态的实例也会因其所保留的硬盘空间而产生少量计费。 如果较长时间内不会重新开启实例，右击图11.16中的示例，选择“Image” $\\rightarrow$ “Create”创建镜像。然后，选择“Instance State” $\\rightarrow$ “Terminate”将实例终结（硬盘不再产生计费）。当下次使用时，我们可按本节中创建并运行EC2实例的步骤重新创建一个基于保存镜像的实例。唯一的区别在于，在图11.10的第一步“1. Chosse AMI”中，我们需要通过左栏“My AMIs”选择之前保存的镜像。这样创建的实例将保留镜像上硬盘的存储，例如无需再安装CUDA和其他运行环境。 小结 我们可以通过云计算服务获取更强大的计算资源来运行本书中的深度学习代码。 练习 云很方便，但不便宜。研究下它的价格，和看看如何节省开销。 扫码直达讨论区","link":"/blog-cn/blog-cn/1f26b7b2/aws/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post 1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/blog-cn/blog-cn/16107/hello-world/"},{"title":"my 3 blog","text":"使用AWS运行代码","link":"/blog-cn/blog-cn/95f91522/my-3-blog/"},{"title":"my 4 blog","text":"使用AWS运行代码","link":"/blog-cn/blog-cn/88fc259a/my-4-blog/"},{"title":"secret blog","text":"使用AWS运行代码","link":"/blog-cn/secret/d9bfec68/secret-blog/"}],"tags":[{"name":"Encrypted","slug":"Encrypted","link":"/blog-cn/tags/Encrypted/"}],"categories":[]}